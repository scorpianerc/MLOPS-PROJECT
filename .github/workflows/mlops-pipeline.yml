name: MLOps CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  
jobs:
  # Job 1: Code Quality & Testing
  quality-check:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black isort
        
    - name: Run linting
      run: |
        echo "Running code quality checks..."
        flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Check code formatting
      run: |
        echo "Checking code formatting..."
        black --check src || echo "Run 'black src' to format code"
        isort --check-only src || echo "Run 'isort src' to sort imports"
        
    - name: Run unit tests
      run: |
        echo "Running unit tests..."
        # Add your test commands here
        # pytest tests/ --cov=src --cov-report=xml
        
    - name: Upload coverage reports
      if: success()
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Job 2: Data Validation
  data-validation:
    runs-on: ubuntu-latest
    needs: quality-check
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install great-expectations
        
    - name: Download NLTK data
      run: |
        python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('punkt_tab')"
        
    - name: Validate data schema
      run: |
        echo "Validating data schema..."
        python -c "
        import pandas as pd
        import os
        
        # Check if raw data exists
        if os.path.exists('data/raw/reviews.csv'):
            df = pd.read_csv('data/raw/reviews.csv')
            print(f'Data shape: {df.shape}')
            print(f'Columns: {list(df.columns)}')
            
            # Validate required columns
            required_cols = ['review_text', 'rating', 'review_date']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                raise ValueError(f'Missing required columns: {missing_cols}')
            
            print('‚úÖ Data validation passed!')
        else:
            print('‚ö†Ô∏è No data file found, skipping validation')
        "

  # Job 3: Model Training & Evaluation
  train-model:
    runs-on: ubuntu-latest
    needs: data-validation
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Download NLTK data
      run: |
        python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('punkt_tab')"
        
    - name: Setup DVC
      run: |
        pip install dvc
        dvc version
        
    - name: Run data pipeline
      run: |
        echo "Running DVC pipeline..."
        # dvc repro
        echo "‚ö†Ô∏è DVC pipeline skipped (no remote storage configured)"
        
    - name: Train model
      run: |
        echo "Training model..."
        if [ -f "data/processed/processed_reviews.csv" ]; then
          python src/training/train.py
        else
          echo "‚ö†Ô∏è No processed data found, skipping training"
        fi
        
    - name: Evaluate model
      run: |
        echo "Evaluating model..."
        if [ -f "models/metrics.json" ]; then
          python -c "
          import json
          with open('models/metrics.json', 'r') as f:
              metrics = json.load(f)
          print('üìä Model Metrics:')
          print(f'  Accuracy: {metrics.get(\"test_accuracy\", 0):.4f}')
          print(f'  F1 Score: {metrics.get(\"test_f1\", 0):.4f}')
          
          # Fail if accuracy is too low
          if metrics.get('test_accuracy', 0) < 0.70:
              raise ValueError('‚ö†Ô∏è Model accuracy below threshold (70%)')
          print('‚úÖ Model meets quality threshold!')
          "
        else
          echo "‚ö†Ô∏è No metrics file found"
        fi
        
    - name: Upload model artifacts
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: model-artifacts
        path: |
          models/*.pkl
          models/*.json
        retention-days: 30

  # Job 4: Build Docker Image
  build-docker:
    runs-on: ubuntu-latest
    needs: train-model
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
      
    - name: Log in to Docker Hub
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
        
    - name: Build Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        file: ./Dockerfile
        push: false
        tags: sentiment-mlops:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Test Docker image
      run: |
        echo "Testing Docker image..."
        docker images

  # Job 5: Deploy (only on main branch)
  deploy:
    runs-on: ubuntu-latest
    needs: build-docker
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Deploy notification
      run: |
        echo "üöÄ Deployment triggered!"
        echo "Branch: ${{ github.ref }}"
        echo "Commit: ${{ github.sha }}"
        
    - name: Create deployment artifact
      run: |
        mkdir -p deployment
        cp docker-compose.yml deployment/
        cp -r grafana deployment/
        cp -r prometheus deployment/
        tar -czf deployment.tar.gz deployment/
        
    - name: Upload deployment artifact
      uses: actions/upload-artifact@v4
      with:
        name: deployment-package
        path: deployment.tar.gz
        retention-days: 7

  # Job 6: Model Registry & Tracking
  model-registry:
    runs-on: ubuntu-latest
    needs: train-model
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        name: model-artifacts
        path: models/
        
    - name: Register model
      run: |
        echo "üìù Registering model to MLflow..."
        echo "Model version: ${{ github.sha }}"
        echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
        
        # Create model metadata
        cat > models/model_metadata.json << EOF
        {
          "version": "${{ github.sha }}",
          "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
          "branch": "${{ github.ref_name }}",
          "author": "${{ github.actor }}",
          "commit_message": "${{ github.event.head_commit.message }}"
        }
        EOF
        
        cat models/model_metadata.json

  # Job 7: Performance Monitoring
  performance-check:
    runs-on: ubuntu-latest
    needs: train-model
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download model artifacts
      uses: actions/download-artifact@v4
      with:
        name: model-artifacts
        path: models/
        
    - name: Check model performance
      run: |
        python -c "
        import json
        import os
        
        if os.path.exists('models/metrics.json'):
            with open('models/metrics.json', 'r') as f:
                metrics = json.load(f)
            
            print('=' * 60)
            print('üìä MODEL PERFORMANCE REPORT')
            print('=' * 60)
            print(f'Test Accuracy:  {metrics.get(\"test_accuracy\", 0):.2%}')
            print(f'Test Precision: {metrics.get(\"test_precision\", 0):.2%}')
            print(f'Test Recall:    {metrics.get(\"test_recall\", 0):.2%}')
            print(f'Test F1 Score:  {metrics.get(\"test_f1\", 0):.2%}')
            print('=' * 60)
            
            # Performance thresholds
            if metrics.get('test_accuracy', 0) >= 0.80:
                print('‚úÖ EXCELLENT - Accuracy >= 80%')
            elif metrics.get('test_accuracy', 0) >= 0.70:
                print('‚úì GOOD - Accuracy >= 70%')
            else:
                print('‚ö†Ô∏è WARNING - Accuracy below 70%')
        else:
            print('‚ö†Ô∏è No metrics file found')
        "

  # Job 8: Create Release
  create-release:
    runs-on: ubuntu-latest
    needs: [deploy, model-registry]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Create Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ github.run_number }}
        release_name: Release v${{ github.run_number }}
        body: |
          ## üöÄ Automated MLOps Release
          
          **Commit:** ${{ github.sha }}
          **Author:** ${{ github.actor }}
          **Timestamp:** ${{ github.event.head_commit.timestamp }}
          
          ### Changes
          ${{ github.event.head_commit.message }}
          
          ### Artifacts
          - Model artifacts
          - Docker image
          - Deployment package
        draft: false
        prerelease: false
